{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from time import time\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "from pytube import YouTube\n",
    "import pytube\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_filename_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n",
    "char_limit = 255\n",
    "\n",
    "def clean_filename(filename, whitelist=valid_filename_chars, replace=' '):\n",
    "    # replace spaces\n",
    "    for r in replace:\n",
    "        filename = filename.replace(r,'_')\n",
    "    \n",
    "    # keep only valid ascii chars\n",
    "    cleaned_filename = unicodedata.normalize('NFKD', filename).encode('ASCII', 'ignore').decode()\n",
    "    \n",
    "    # keep only whitelisted chars\n",
    "    cleaned_filename = ''.join(c for c in cleaned_filename if c in whitelist)\n",
    "    if len(cleaned_filename)>char_limit:\n",
    "        print(\"Warning, filename truncated because it was over {}. Filenames may no longer be unique\".format(char_limit))\n",
    "    return cleaned_filename[:char_limit]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Trailer for Dumbo\n",
      "The Dirt only has 1 page of movie reviews\n",
      "No Trailer for The Dirt\n",
      "No Trailer for Escape Room\n",
      "Avengers: Infinity War only has 1 page of movie reviews\n",
      "No Trailer for Avengers: Infinity War\n",
      "No Trailer for Spider-Man: Into the Spider-Verse\n",
      "No Trailer for Pet Sematary\n",
      "No Trailer for The Mule\n",
      "No Trailer for Bumblebee\n",
      "No Trailer for Unplanned\n",
      "No Trailer for Triple Frontier\n"
     ]
    }
   ],
   "source": [
    "# Store data in lists\n",
    "names = []\n",
    "runtimes = []\n",
    "profile_pages = []\n",
    "release_dates = []\n",
    "budgets = []\n",
    "plot_synopsis = []\n",
    "production_companies = []\n",
    "spec_eff_comps = []\n",
    "gross = []\n",
    "stars = []\n",
    "directors = []\n",
    "screen_writers = []\n",
    "metascores = []\n",
    "genres = []\n",
    "mpaa_ratings = []\n",
    "imdb_ratings = []\n",
    "movie_awards = []\n",
    "movie_reviews = []\n",
    "sub_samples = []\n",
    "first_weekend_USA = []\n",
    "full_cast = []\n",
    "\n",
    "# pages = [str(i) for i in range(1,140000,250)]\n",
    "\n",
    "pages = [str(i) for i in range(1,140000,250)]\n",
    "\n",
    "\n",
    "#Prepare monitoring of loop\n",
    "start_time = time()\n",
    "requests = 0\n",
    "#for every page\n",
    "for page in pages:\n",
    "\n",
    "    #make get request\n",
    "    response = get(\"https://www.imdb.com/search/title?title_type=feature&languages=en&count=250&start=\" + page)\n",
    "\n",
    "    #pause the loop\n",
    "    sleep(randint(8,15))\n",
    "\n",
    "    #monitor requests\n",
    "    requests += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "    clear_output(wait = True)\n",
    "\n",
    "    #throw a warning for non-200 status codes\n",
    "    if response.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "\n",
    "    #break the loop if the number of requests is greater than expected\n",
    "    if requests > 72:\n",
    "        warn('Number of requests was greater than expected.')\n",
    "        break\n",
    "\n",
    "    # parse the content of request\n",
    "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    #select all 250 movie containers from a single page\n",
    "    mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "#     del mv_containers[:16]\n",
    "    # Extract data from indiv. movie containers\n",
    "    for container in mv_containers:\n",
    "        if container.find('div', class_ = 'ratings-metascore') is not None:\n",
    "            #Name\n",
    "            name = container.h3.a.text\n",
    "            names.append(name)\n",
    "            \n",
    "            linkzor = container.h3.a['href']\n",
    "            \n",
    "            castz = get(\"https://www.imdb.com/\" + linkzor + \"fullcredits\")\n",
    "            # parse the content of request\n",
    "            cast_html = BeautifulSoup(castz.text, 'html.parser')\n",
    "            \n",
    "            try: \n",
    "                #cast\n",
    "                cast_html.find('table', class_ = 'cast_list').findNext('tr').decompose()\n",
    "                cast_members = []\n",
    "                cast_odd = cast_html.find('table', class_ = 'cast_list').findAll('tr', class_='odd')\n",
    "                cast_even = cast_html.find('table', class_ = 'cast_list').findAll('tr', class_='even')\n",
    "                for cast in cast_odd:\n",
    "                    cast_members.append(cast.findAll('td')[1].text.strip())\n",
    "                for cast in cast_even:\n",
    "                    cast_members.append(cast.findAll('td')[1].text.strip())\n",
    "                full_cast.append(cast_members)\n",
    "            except:\n",
    "                full_cast.append('null')\n",
    "            \n",
    "            #Runtime\n",
    "            runtime = container.find('span', class_ = 'runtime').text\n",
    "            runtimes.append(runtime)\n",
    "                        \n",
    "            #Stars\n",
    "            movie_stars = []\n",
    "            stars_x = container.findAll('div')[3].findAll('p')[2].findAll('a')\n",
    "            del stars_x[0]\n",
    "            for star in stars_x:\n",
    "                movie_stars.append(star.text)\n",
    "            stars.append(movie_stars)\n",
    "\n",
    "            #Profile\n",
    "            sleep(randint(1,3))\n",
    "            profile = container.h3.a['href']\n",
    "            profile_pages.append(profile)\n",
    "\n",
    "            details = get(\"https://www.imdb.com/\" + profile)\n",
    "            # parse the content of request\n",
    "            details_html = BeautifulSoup(details.text, 'html.parser')\n",
    "            \n",
    "            try:\n",
    "                #opening weekend BO\n",
    "                bo = details_html.find(text='Opening Weekend USA:').parent.findNext('span').decompose()\n",
    "                bo = details_html.find(text='Opening Weekend USA:').parent.findNext('span').decompose()\n",
    "                ow_bo = details_html.find(text='Opening Weekend USA:').parent.parent.text.strip()\n",
    "                first_weekend_USA.append(ow_bo[20:].replace('$', '').replace(',', '').strip())\n",
    "            except:\n",
    "                first_weekend_USA.append(\"null\")\n",
    "\n",
    "            #save storyline\n",
    "#             storyline = details_html.find(\"div\", {\"id\": \"titleStoryLine\"}).div.span.text\n",
    "#             storylines.append(storyline)\n",
    "            \n",
    "            try:\n",
    "                #Budget\n",
    "                bo_budget = details_html.find(text='Budget:').parent.findNext('span').decompose()\n",
    "                budget = details_html.find(text='Budget:').parent.parent.text.strip()\n",
    "                budgets.append(budget[7:].replace('$', '').replace(',', ''))\n",
    "            except:\n",
    "                budgets.append(\"null\")\n",
    "                    \n",
    "            #Release Dates\n",
    "            html_text = \"Release Date:\"\n",
    "            details_html.find(text='Release Date:').parent.findNext('span').decompose()\n",
    "            date = details_html.find(text='Release Date:').parent.parent.text.strip()\n",
    "            release_dates.append(re.sub(r'\\([^)]*\\)', '', date[14:])[:-1])\n",
    "            \n",
    "#             movie_name = name\n",
    "#             award = get(\"https://www.boxofficemojo.com/oscar/movies/?id={}.htm\".format(movie_name.replace(\" \", \"\")))\n",
    "#             html_awards = BeautifulSoup(award.text, 'html.parser')\n",
    "#             award_links = html_awards.find(\"div\", {\"id\": \"body\"}).find_all('a')\n",
    "#             awards = {}\n",
    "#             for award in award_links:\n",
    "#                 if \"(WIN)\" in award.text:\n",
    "#                     link = \"https://www.boxofficemojo.com/{}\".format(award['href'])\n",
    "#                     new_url = link\n",
    "#                     new_response = get(link)\n",
    "#                     html_award = BeautifulSoup(new_response.text, 'html.parser')\n",
    "#                     html_award.find('font').extract()\n",
    "#                     title = html_award.find('font').text\n",
    "#                     if title == \"BEST PICTURE\":\n",
    "#                         awards[title] = movie_name\n",
    "#                     else:\n",
    "#                         awards[title] = html_award.find(text=movie_name).findNext('font').text\n",
    "            \n",
    "            #Production Companies\n",
    "            production_comps = []\n",
    "            sleep(randint(1,3))\n",
    "            production_link = profile\n",
    "            production = get(\"https://www.imdb.com/\" + production_link + \"companycredits\")\n",
    "            production_html = BeautifulSoup(production.text, 'html.parser')\n",
    "            comps_x = production_html.find(\"div\", {\"id\": \"company_credits_content\"}).ul.findAll('a')\n",
    "            for comp in comps_x:\n",
    "                production_comps.append(comp.text)\n",
    "            production_companies.append(production_comps)\n",
    "            \n",
    "            #Special Effects Companies            \n",
    "            effects = get(\"https://www.imdb.com/{}companycredits\".format(profile))\n",
    "            effects_html = BeautifulSoup(effects.text, 'html.parser')\n",
    "\n",
    "            \n",
    "            if effects_html.find(\"h4\", {\"id\": \"specialEffects\"}):\n",
    "                effects_comps = []\n",
    "                comps_x = effects_html.find(\"h4\", {\"id\": \"specialEffects\"}).findNext('ul').findAll('li')\n",
    "                for comp in comps_x:\n",
    "                    effects_comps.append(comp.a.text)\n",
    "                spec_eff_comps.append(effects_comps)\n",
    "            else:\n",
    "                spec_eff_comps.append(\"null\")\n",
    "            #Director\n",
    "            director = container.findAll('div')[3].findAll('p')[2].findAll('a')[0].text\n",
    "            directors.append(director)\n",
    "\n",
    "\n",
    "            synopsis_link = profile\n",
    "            sleep(randint(1,3))\n",
    "            synopsis = get(\"https://www.imdb.com/\" + synopsis_link + \"plotsummary\")\n",
    "            synopsis_html = BeautifulSoup(synopsis.text, 'html.parser')\n",
    "\n",
    "            plot_synopsis_content = synopsis_html.find(\"ul\", {\"id\": \"plot-synopsis-content\"}).li.text\n",
    "            plot_synopsis_content = plot_synopsis_content.strip()\n",
    "            plot_synopsis.append(plot_synopsis_content)\n",
    "            \n",
    "            writers = []\n",
    "            sleep(randint(1,3))\n",
    "            credits = get(\"https://www.imdb.com/{}fullcredits\".format(profile))\n",
    "            credits_html = BeautifulSoup(credits.text, 'html.parser')\n",
    "            credit_containers = credits_html.find_all('table', class_ = 'simpleTable simpleCreditsTable')\n",
    "            writers_x = credit_containers[1].tbody.findAll('tr')\n",
    "            for writer in writers_x:\n",
    "                if writer.find('td', attrs = {'colspan':'3'}):\n",
    "                    1==1\n",
    "                else:\n",
    "                    answer = writer.find('td', class_ = 'name').text\n",
    "                    writers.append(answer.strip())\n",
    "            screen_writers.append(writers)\n",
    "            \n",
    "            \n",
    "            #Metascore\n",
    "            metascore = container.find('span', class_ = 'metascore')\n",
    "            metascore = int(metascore.text)\n",
    "            metascores.append(metascore)\n",
    "\n",
    "            \n",
    "            #Genre\n",
    "            genre = container.p.find('span', class_ = 'genre').text.strip()\n",
    "            genres.append(genre)\n",
    "            \n",
    "            if container.p.find('span', class_ = 'certificate') is not None:\n",
    "                #MPAA rating\n",
    "                mpaa = container.p.find('span', class_ = 'certificate').text\n",
    "                mpaa_ratings.append(mpaa)\n",
    "            else:\n",
    "                na = \"N/A\"\n",
    "                mpaa_ratings.append(na)\n",
    "                \n",
    "            #IMDb rating\n",
    "            imdb = float(container.strong.text)\n",
    "            imdb_ratings.append(imdb)\n",
    "            \n",
    "            try:\n",
    "                #Gross\n",
    "                bo_gross = container.findAll('div')[3].findAll('p')[3].findAll('span')[4]\n",
    "                bo_gross = bo_gross['data-value']\n",
    "                bo_gross = re.sub(\"[^\\d\\.]\", \"\", bo_gross)\n",
    "                gross.append(int(bo_gross))\n",
    "            except:\n",
    "                gross.append(\"null\")\n",
    "                \n",
    "            comments = []\n",
    "            reviews_link = profile\n",
    "            all_reviews = get(\"https://www.imdb.com/\" + reviews_link + \"reviews\")\n",
    "            html_reviews = BeautifulSoup(all_reviews.text, 'html.parser')\n",
    "            num_reviews = int(html_reviews.find(\"div\", {\"id\": \"main\"}).section.find('div', class_ = 'lister').span.text[:-7].strip().replace(',', ''))\n",
    "            math.ceil(num_reviews/25) -1\n",
    "\n",
    "    \n",
    "            driver = webdriver.Chrome(\"C:\\\\Users\\Brian\\Downloads\\chromedriver\\chromedriver.exe\")\n",
    "            driver.get(\"https://www.imdb.com/\" + reviews_link + \"reviews\")\n",
    "            sleep(randint(3,3))\n",
    "            try:\n",
    "                button = driver.find_element_by_id('load-more-trigger')\n",
    "                for i in range(math.ceil(num_reviews/25) - 1):\n",
    "                    button.click()\n",
    "                    sleep(randint(1,1))\n",
    "            except:\n",
    "                print('{} only has 1 page of movie reviews'.format(name))\n",
    "            src = driver.page_source\n",
    "            parser = BeautifulSoup(src, 'lxml')\n",
    "            list_of_attributes = {\"class\":\"lister-item\"}\n",
    "            review_containers = parser.findAll(\"div\", attrs=list_of_attributes)\n",
    "            for container in review_containers:\n",
    "                comments.append(container.div.div.find(\"div\", class_ = \"content\").div.text)\n",
    "            movie_reviews.append(comments)\n",
    "\n",
    "            driver.close()\n",
    "            \n",
    "            #Trailer\n",
    "            movie_name = name\n",
    "            response = get(\"https://www.google.com/search?q={}+Trailer\".format(movie_name.replace(\" \", \"+\")))\n",
    "            html_google = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            try:\n",
    "                txt = html_google.find('div', class_='g').text\n",
    "                x = re.findall(\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\",txt)\n",
    "                link = \"{}://{}{}\".format(x[0][0], x[0][1], x[0][2])\n",
    "                yt = pytube.YouTube(link)\n",
    "                stream = yt.streams.first()\n",
    "                os.mkdir(\"C:\\\\Users\\Brian\\OneDrive - Southern Connecticut State University\\Movie_Data\\Movie_Trailers\\{}\".format(clean_filename(movie_name)))\n",
    "                stream.download(\"C:\\\\Users\\Brian\\OneDrive - Southern Connecticut State University\\Movie_Data\\Movie_Trailers\\{}\".format(clean_filename(movie_name)), \"{}_trailer\".format(clean_filename(movie_name)))\n",
    "            except:\n",
    "                print('No Trailer for {}'.format(name))\n",
    "#             #Sub Sample Extraction\n",
    "#             def FrameCapture(path): \n",
    "\n",
    "#                 # Path to video file \n",
    "#                 vidObj = cv2.VideoCapture(path) \n",
    "\n",
    "#                 # Used as counter variable \n",
    "#                 count = 0\n",
    "\n",
    "#                 # checks whether frames were extracted \n",
    "#                 success = 1\n",
    "\n",
    "#                 while success: \n",
    "#                     # vidObj object calls read \n",
    "#                     # function extract frames \n",
    "#                     success, image = vidObj.read() \n",
    "\n",
    "#                     # Saves the frames with frame-count\n",
    "#                     if count % 2 == 0:\n",
    "#                         cv2.imwrite(\"C:\\\\Users\\\\Brian\\\\Desktop\\\\IMDb_Scrape\\\\Movie_Trailers\\\\{}\\\\frame%d.jpeg\".format(clean_filename(movie_name)) % count, image) \n",
    "\n",
    "#                     count += 1\n",
    "#             try:\n",
    "#                 if __name__ == '__main__': \n",
    "\n",
    "#                     # Calling the function \n",
    "#                     FrameCapture(\"C:\\\\Users\\\\Brian\\\\Desktop\\\\IMDb_Scrape\\\\Movie_Trailers\\\\{}\\\\{}_trailer.mp4\".format(clean_filename(movie_name), clean_filename(movie_name))) \n",
    "#             except:\n",
    "#                 sub_samples.append(clean_filename(movie_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request:1; Frequency: 0.08826853323335623 requests/s\n"
     ]
    }
   ],
   "source": [
    "# Store data in lists\n",
    "names = []\n",
    "full_cast = []\n",
    "\n",
    "# pages = [str(i) for i in range(1,141000,250)]\n",
    "pages = ['1']\n",
    "\n",
    "#Prepare monitoring of loop\n",
    "start_time = time()\n",
    "requests = 0\n",
    "#for every page\n",
    "for page in pages:\n",
    "\n",
    "    #make get request\n",
    "    response = get(\"https://www.imdb.com/search/title?title_type=feature&languages=en&count=50&start=\" + page)\n",
    "\n",
    "    #pause the loop\n",
    "    sleep(randint(8,15))\n",
    "\n",
    "    #monitor requests\n",
    "    requests += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "    clear_output(wait = True)\n",
    "\n",
    "    #throw a warning for non-200 status codes\n",
    "    if response.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "\n",
    "    #break the loop if the number of requests is greater than expected\n",
    "    if requests > 72:\n",
    "        warn('Number of requests was greater than expected.')\n",
    "        break\n",
    "\n",
    "    # parse the content of request\n",
    "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    #select all 250 movie containers from a single page\n",
    "    mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "    del mv_containers[:25]\n",
    "    # Extract data from indiv. movie containers\n",
    "    for container in mv_containers:\n",
    "        if container.find('div', class_ = 'ratings-metascore') is not None:\n",
    "            #Name\n",
    "            name = container.h3.a.text\n",
    "            names.append(name)\n",
    "            \n",
    "            linkzor = container.h3.a['href']\n",
    "            \n",
    "            castz = get(\"https://www.imdb.com/\" + linkzor[:-15] + \"fullcredits\")\n",
    "            # parse the content of request\n",
    "            cast_html = BeautifulSoup(castz.text, 'html.parser')\n",
    "            \n",
    "            #cast\n",
    "            cast_html.find('table', class_ = 'cast_list').findNext('tr').decompose()\n",
    "            cast_members = []\n",
    "            cast_odd = cast_html.find('table', class_ = 'cast_list').findAll('tr', class_='odd')\n",
    "            cast_even = cast_html.find('table', class_ = 'cast_list').findAll('tr', class_='even')\n",
    "            for cast in cast_odd:\n",
    "                cast_members.append(cast.findAll('td')[1].text.strip())\n",
    "            for cast in cast_even:\n",
    "                cast_members.append(cast.findAll('td')[1].text.strip())\n",
    "            full_cast.append(cast_members)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names Length: 17\n",
      "Cast Length: 17\n"
     ]
    }
   ],
   "source": [
    "print(\"Names Length: {}\".format(len(names)))\n",
    "print(\"Cast Length: {}\".format(len(full_cast)))\n",
    "# print(\"Opening Weekend: {}\".format(len(first_weekend_USA)))\n",
    "# print(\"Length: {}\".format(len(runtimes)))\n",
    "# print(\"Profile: {}\".format(len(profile_pages)))\n",
    "# print(\"Spe. Eff.: {}\".format(len(spec_eff_comps)))\n",
    "# print(\"Date: {}\".format(len(release_dates)))\n",
    "# print(\"Budget: {}\".format(len(budgets)))\n",
    "# print(\"Synopsis: {}\".format(len(plot_synopsis)))\n",
    "# print(\"Pro. Comp: {}\".format(len(production_companies)))\n",
    "# print(\"Gross Length: {}\".format(len(gross)))\n",
    "# print(\"Stars: {}\".format(len(stars)))\n",
    "# print(\"Director Length: {}\".format(len(directors)))\n",
    "# print(\"Screen Writers Length: {}\".format(len(screen_writers)))\n",
    "# print(\"Metascore: {}\".format(len(metascores)))\n",
    "# print(\"Genre: {}\".format(len(genres)))\n",
    "# print(\"MPAA: {}\".format(len(mpaa_ratings)))\n",
    "# print(\"IMDB: {}\".format(len(imdb_ratings)))\n",
    "# print(\"Comments: {}\".format(len(movie_reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 2 columns):\n",
      "movie    17 non-null object\n",
      "cast     17 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 352.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary Poppins Returns</td>\n",
       "      <td>[Emily Blunt, Ben Whishaw, Pixie Davies, Joel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Favourite</td>\n",
       "      <td>[Olivia Colman, Emma Delves, Emma Stone, Jenni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get Out</td>\n",
       "      <td>[Daniel Kaluuya, Catherine Keener, Caleb Landr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deadpool 2</td>\n",
       "      <td>[Ryan Reynolds, Morena Baccarin, Zazie Beetz, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to Train Your Dragon: The Hidden World</td>\n",
       "      <td>[Jay Baruchel, F. Murray Abraham, Gerard Butle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mortal Engines</td>\n",
       "      <td>[Hera Hilmar, Hugo Weaving, Ronan Raftery, Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Instant Family</td>\n",
       "      <td>[Mark Wahlberg, Isabela Moner, Julianna Gamiz,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vice</td>\n",
       "      <td>[Christian Bale, Steve Carell, Alison Pill, Ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wonder Park</td>\n",
       "      <td>[Sofia Mali, Ken Hudson Campbell, Mila Kunis, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stan &amp; Ollie</td>\n",
       "      <td>[Steve Coogan, Shirley Henderson, Rufus Jones,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        movie  \\\n",
       "0                        Mary Poppins Returns   \n",
       "1                               The Favourite   \n",
       "2                                     Get Out   \n",
       "3                                  Deadpool 2   \n",
       "4  How to Train Your Dragon: The Hidden World   \n",
       "5                              Mortal Engines   \n",
       "6                              Instant Family   \n",
       "7                                        Vice   \n",
       "8                                 Wonder Park   \n",
       "9                                Stan & Ollie   \n",
       "\n",
       "                                                cast  \n",
       "0  [Emily Blunt, Ben Whishaw, Pixie Davies, Joel ...  \n",
       "1  [Olivia Colman, Emma Delves, Emma Stone, Jenni...  \n",
       "2  [Daniel Kaluuya, Catherine Keener, Caleb Landr...  \n",
       "3  [Ryan Reynolds, Morena Baccarin, Zazie Beetz, ...  \n",
       "4  [Jay Baruchel, F. Murray Abraham, Gerard Butle...  \n",
       "5  [Hera Hilmar, Hugo Weaving, Ronan Raftery, Pat...  \n",
       "6  [Mark Wahlberg, Isabela Moner, Julianna Gamiz,...  \n",
       "7  [Christian Bale, Steve Carell, Alison Pill, Ju...  \n",
       "8  [Sofia Mali, Ken Hudson Campbell, Mila Kunis, ...  \n",
       "9  [Steve Coogan, Shirley Henderson, Rufus Jones,...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings = pd.DataFrame({'movie': names,\n",
    "                              'cast': full_cast\n",
    "#                               'first_weekend': first_weekend_USA\n",
    "#                               'length': runtimes,\n",
    "# #                               'profile': profile_pages,\n",
    "#                               'date': release_dates,\n",
    "#                               'budget': budgets,\n",
    "#                               'synopsis': plot_synopsis,\n",
    "#                               'pro. comp': production_companies,\n",
    "#                               'spec. eff': spec_eff_comps,\n",
    "#                                 'gross': gross,\n",
    "#                               'stars': stars,\n",
    "#                         'director': directors,\n",
    "#                         'writer': screen_writers,\n",
    "#                              'metascore': metascores,\n",
    "#                               'genre': genres,\n",
    "#                               'mpaa': mpaa_ratings,\n",
    "#                               'imdb': imdb_ratings,\n",
    "#                               'reviews': movie_reviews\n",
    "                             })\n",
    "\n",
    "print(movie_ratings.info())\n",
    "movie_ratings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Double Negative (DNEG)',\n",
       " 'Halo VFX',\n",
       " 'Argon Effects',\n",
       " 'Clear Angle Studios',\n",
       " 'Centroid Motion Capture',\n",
       " 'The Visual Effects Company',\n",
       " 'Fangs FX']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.imdb.com/title/tt1727824/companycredits\"\n",
    "response = get(url)\n",
    "\n",
    "effects_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "effects_comps = []\n",
    "comps_x = effects_html.find(\"h4\", {\"id\": \"specialEffects\"}).findNext('ul').findAll('li')\n",
    "for comp in comps_x:\n",
    "    effects_comps.append(comp.a.text)\n",
    "effects_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findNext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-3d6834ca4118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mmovie_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mawards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml_award\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"{} ({})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovie_year\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindNext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'font'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0maward_links\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml_awards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"body\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findNext'"
     ]
    }
   ],
   "source": [
    "movie_name = \"Alita: Battle Angel\"\n",
    "movie_year = \"2019\"\n",
    "url_1 = \"https://www.boxofficemojo.com/oscar/movies/?id={}.htm\".format(movie_name.replace(\" \", \"\"))\n",
    "response_1 = get(url_1)\n",
    "html_awards = BeautifulSoup(response_1.text, 'html.parser')\n",
    "if html_awards.find(\"div\", {\"id\": \"body\"}).h1.text not in [movie_name, \"{} ({})\".format(movie_name, movie_year)]:\n",
    "    url_1 = \"https://www.boxofficemojo.com/oscar/movies/?id={}{}.htm\".format(movie_name.replace(\" \", \"\"),movie_year)\n",
    "    response_1 = get(url_1)\n",
    "    html_awards = BeautifulSoup(response_1.text, 'html.parser')\n",
    "    blah = []\n",
    "    award_links = html_awards.find(\"div\", {\"id\": \"body\"}).find_all('a')\n",
    "    awards = {}\n",
    "    for award in award_links:\n",
    "        if \"(WIN)\" in award.text:\n",
    "            link = \"https://www.boxofficemojo.com/{}\".format(award['href'])\n",
    "            new_url = link\n",
    "            new_response = get(link)\n",
    "            html_award = BeautifulSoup(new_response.text, 'html.parser')\n",
    "            html_award.find('font').extract()\n",
    "            title = html_award.find('font').text\n",
    "            if title == \"BEST PICTURE\":\n",
    "                awards[title] = movie_name\n",
    "            else:\n",
    "                movie_name\n",
    "                awards[title] = html_award.find(text=\"{} ({})\".format(movie_name, movie_year)).findNext('font').text\n",
    "else:\n",
    "    award_links = html_awards.find(\"div\", {\"id\": \"body\"}).find_all('a')\n",
    "    awards = {}\n",
    "    for award in award_links:\n",
    "        if \"(WIN)\" in award.text:\n",
    "            link = \"https://www.boxofficemojo.com/{}\".format(award['href'])\n",
    "            new_url = link\n",
    "            new_response = get(link)\n",
    "            html_award = BeautifulSoup(new_response.text, 'html.parser')\n",
    "            html_award.find('font').extract()\n",
    "            title = html_award.find('font').text\n",
    "            if title == \"BEST PICTURE\":\n",
    "                awards[title] = movie_name\n",
    "            else:\n",
    "                awards[title] = html_award.find(text=movie_name).findNext('font').text\n",
    "print(awards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "comments = []\n",
    "\n",
    "\n",
    "url = \"https://www.imdb.com/title/tt7343762/reviews\"\n",
    "response = get(url)\n",
    "html_reviews = BeautifulSoup(response.text, 'html.parser')\n",
    "# print(html_reviews.find(\"div\", {\"id\": \"main\"}))\n",
    "# print(html_reviews.find(\"div\", {\"id\": \"main\"}).section)\n",
    "# print(html_reviews.find(\"div\", {\"id\": \"main\"}).section.find('div', class_ = 'lister').span)\n",
    "print(html_reviews.find(\"div\", {\"id\": \"main\"}).section.find('div', class_ = 'lister').span.text[:-7].strip().replace(',', ''))\n",
    "# num_reviews = int(html_reviews.find(\"div\", {\"id\": \"main\"}).section.find('div', class_ = 'lister').span.text[:-8].replace(',', ''))\n",
    "# math.ceil(num_reviews/25) -1\n",
    "\n",
    "\n",
    "# driver = webdriver.Chrome(\"C:\\\\Users\\Brian\\Downloads\\chromedriver\\chromedriver.exe\")\n",
    "# driver.get(\"https://www.imdb.com/title/tt7343762/reviews\")\n",
    "# try:\n",
    "#     button = driver.find_element_by_id('load-more-trigger')\n",
    "#     for i in range(math.ceil(num_reviews/25) - 1):\n",
    "#         button.click()\n",
    "#         sleep(randint(1,1))\n",
    "# except:\n",
    "#     print(\"Only 1 page of reviews\")\n",
    "# src = driver.page_source\n",
    "# parser = BeautifulSoup(src, 'lxml')\n",
    "# list_of_attributes = {\"class\":\"lister-item\"}\n",
    "# review_containers = parser.findAll(\"div\", attrs=list_of_attributes)\n",
    "# for container in review_containers:\n",
    "#     comments.append(container.div.div.find(\"div\", class_ = \"content\").div.text)\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I hate how people in horror movies do dumb stuff. Like go upstairs instead of trying to use the back door and making it outside. The characters do the same thing here specifically the kids. It's frustrating on how bad the writing was. Like why would you do that? It has so much potential. Cinematography and production really stand out for me. The pale colors and the set pieces I really enjoy. The story is as simple as it gets. CPS case worker goes to discover 2 children dead in a canal. She has to take her children with her, even though the boy is old enough to babysit. Then the boy goes on an adventure and wants to be nosy. Then he encounters The vengeful spirit La Llarona and gets his sister and mother cursed. Then the mom looks for help to stop her from taking her children. I swear I've seen this before. The Jump scares still kind of get you, even though you see them coming. It's the same old, same old. Im very worried for the conjuring 3 now. I hope they get new writers.\",\n",
       " \"I'm always give much expectation for JAMES's horror movie series but this is another one that makes me disappointed...At least better than THE NUN.\\nHope the next film would brings us more surprising.\",\n",
       " \"This was boring and predictable.\\nThe ghost was shown too much.\\nThe set pieces felt repetitive.\\nThe main characters didn't go on any kind of transformation/arc.\\nPlease don't make another movie this tired New Line/Atomic. Please!\",\n",
       " \"Little twist and trademark's jump scare by James Aan\",\n",
       " \"Personally I was expecting this movie to be in the 6-8/10 range so it was a bit underwhelming for me. The film felt much longer than it was and looking at the clock after leaving and it was fairly short at around 90 minutes. I felt as though I was sitting there for about 2 hours and half of that time I was fairly bored. There were only perhaps one or two moments where I felt scared and even then it was only very mild and for a few seconds when a jump scare had occurred. It's worth noting that I am not familiar with the source material / urban legend so it's not a story that has any personal meaning to me. I found the setting of 1970s LA quite bland even though it shouldn't have been and the characters generally uninteresting including the monster. I don't mind the idea of the monster's origin story but it's still not really interesting enough to carry a whole film in my opinion, unless it was done really really well. I think had the film been set somewhere more isolated it would have helped a lot. There is not a whole lot to like about the film for me apart from a few decent scenes and the stereotypical horror film moments of stupidity are there for a few unintentional laughs along the way. I'd say the film is worth a watch for horror fans but I'm not sure it's really worth the price of entry so see if you can watch it another way at some point in the future.\",\n",
       " 'I like to scare myself and The Curse of La Llorona is the scary fun. Since then, I no longer dare to go to the cellar alone.',\n",
       " 'This movie is enough to make you have a nightmare.. good directing, making horror and tension collaborating perfectly.. Bravo !! 👏🏼 #Lallorona',\n",
       " \"All the clichés of the genre, the weeping woman turns quickly and it breaks bones, that even shows up in the trailer when the child sees her, jump cheap scares and all the same old things that people of today like, like for example everything is silent, suddenly a loud sound and she appears behind you in the shadows. TOTALLY PREDICTABLE. When the girl looks out the door I already knew it was for her doll and voila, that was it. Everything is fortuitous. The stupid shaman that is trying to be funny, the kids behaving so foolish that everyone in the room wanted to punch them, people laughed and they were angry (but that's the script's fault). The other mexican crazy lady that becomes bad and vindictive in order to finish the others, and in the end is redeemed from one moment to another because the plot says. This movie is like a Mexican fast food in the USA that you find in a corner, which is not the REAL FOOD in Mexico. It has good things and I know that there are people who like this kind of cheap fear, and there were some who got scared in the room and even shouted and covered their faces. SPOILER: In the end they kill La Llorona, that's like killing The Bogeyman, totally absurd, that's an urban legend in all Latin America, a folklore, a woman who lost her children and is walking around kidnapping others. You can't kill Baba Yaga.\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15001',\n",
       " '15251',\n",
       " '15501',\n",
       " '15751',\n",
       " '16001',\n",
       " '16251',\n",
       " '16501',\n",
       " '16751',\n",
       " '17001',\n",
       " '17251',\n",
       " '17501',\n",
       " '17751',\n",
       " '18001',\n",
       " '18251',\n",
       " '18501',\n",
       " '18751',\n",
       " '19001',\n",
       " '19251',\n",
       " '19501',\n",
       " '19751',\n",
       " '20001',\n",
       " '20251',\n",
       " '20501',\n",
       " '20751',\n",
       " '21001',\n",
       " '21251',\n",
       " '21501',\n",
       " '21751',\n",
       " '22001',\n",
       " '22251',\n",
       " '22501',\n",
       " '22751',\n",
       " '23001',\n",
       " '23251',\n",
       " '23501',\n",
       " '23751',\n",
       " '24001',\n",
       " '24251',\n",
       " '24501',\n",
       " '24751',\n",
       " '25001',\n",
       " '25251',\n",
       " '25501',\n",
       " '25751',\n",
       " '26001',\n",
       " '26251',\n",
       " '26501',\n",
       " '26751',\n",
       " '27001',\n",
       " '27251',\n",
       " '27501',\n",
       " '27751',\n",
       " '28001',\n",
       " '28251',\n",
       " '28501',\n",
       " '28751',\n",
       " '29001',\n",
       " '29251',\n",
       " '29501',\n",
       " '29751',\n",
       " '30001',\n",
       " '30251',\n",
       " '30501',\n",
       " '30751',\n",
       " '31001',\n",
       " '31251',\n",
       " '31501',\n",
       " '31751',\n",
       " '32001',\n",
       " '32251',\n",
       " '32501',\n",
       " '32751',\n",
       " '33001',\n",
       " '33251',\n",
       " '33501',\n",
       " '33751',\n",
       " '34001',\n",
       " '34251',\n",
       " '34501',\n",
       " '34751',\n",
       " '35001',\n",
       " '35251',\n",
       " '35501',\n",
       " '35751',\n",
       " '36001',\n",
       " '36251',\n",
       " '36501',\n",
       " '36751',\n",
       " '37001',\n",
       " '37251',\n",
       " '37501',\n",
       " '37751',\n",
       " '38001',\n",
       " '38251',\n",
       " '38501',\n",
       " '38751',\n",
       " '39001',\n",
       " '39251',\n",
       " '39501',\n",
       " '39751',\n",
       " '40001',\n",
       " '40251',\n",
       " '40501',\n",
       " '40751',\n",
       " '41001',\n",
       " '41251',\n",
       " '41501',\n",
       " '41751',\n",
       " '42001',\n",
       " '42251',\n",
       " '42501',\n",
       " '42751',\n",
       " '43001',\n",
       " '43251',\n",
       " '43501',\n",
       " '43751',\n",
       " '44001',\n",
       " '44251',\n",
       " '44501',\n",
       " '44751',\n",
       " '45001',\n",
       " '45251',\n",
       " '45501',\n",
       " '45751',\n",
       " '46001',\n",
       " '46251',\n",
       " '46501',\n",
       " '46751',\n",
       " '47001',\n",
       " '47251',\n",
       " '47501',\n",
       " '47751',\n",
       " '48001',\n",
       " '48251',\n",
       " '48501',\n",
       " '48751',\n",
       " '49001',\n",
       " '49251',\n",
       " '49501',\n",
       " '49751',\n",
       " '50001',\n",
       " '50251',\n",
       " '50501',\n",
       " '50751',\n",
       " '51001',\n",
       " '51251',\n",
       " '51501',\n",
       " '51751',\n",
       " '52001',\n",
       " '52251',\n",
       " '52501',\n",
       " '52751',\n",
       " '53001',\n",
       " '53251',\n",
       " '53501',\n",
       " '53751',\n",
       " '54001',\n",
       " '54251',\n",
       " '54501',\n",
       " '54751',\n",
       " '55001',\n",
       " '55251',\n",
       " '55501',\n",
       " '55751',\n",
       " '56001',\n",
       " '56251',\n",
       " '56501',\n",
       " '56751',\n",
       " '57001',\n",
       " '57251',\n",
       " '57501',\n",
       " '57751',\n",
       " '58001',\n",
       " '58251',\n",
       " '58501',\n",
       " '58751',\n",
       " '59001',\n",
       " '59251',\n",
       " '59501',\n",
       " '59751',\n",
       " '60001',\n",
       " '60251',\n",
       " '60501',\n",
       " '60751',\n",
       " '61001',\n",
       " '61251',\n",
       " '61501',\n",
       " '61751',\n",
       " '62001',\n",
       " '62251',\n",
       " '62501',\n",
       " '62751',\n",
       " '63001',\n",
       " '63251',\n",
       " '63501',\n",
       " '63751',\n",
       " '64001',\n",
       " '64251',\n",
       " '64501',\n",
       " '64751',\n",
       " '65001',\n",
       " '65251',\n",
       " '65501',\n",
       " '65751',\n",
       " '66001',\n",
       " '66251',\n",
       " '66501',\n",
       " '66751',\n",
       " '67001',\n",
       " '67251',\n",
       " '67501',\n",
       " '67751',\n",
       " '68001',\n",
       " '68251',\n",
       " '68501',\n",
       " '68751',\n",
       " '69001',\n",
       " '69251',\n",
       " '69501',\n",
       " '69751',\n",
       " '70001',\n",
       " '70251',\n",
       " '70501',\n",
       " '70751',\n",
       " '71001',\n",
       " '71251',\n",
       " '71501',\n",
       " '71751',\n",
       " '72001',\n",
       " '72251',\n",
       " '72501',\n",
       " '72751',\n",
       " '73001',\n",
       " '73251',\n",
       " '73501',\n",
       " '73751',\n",
       " '74001',\n",
       " '74251',\n",
       " '74501',\n",
       " '74751',\n",
       " '75001',\n",
       " '75251',\n",
       " '75501',\n",
       " '75751',\n",
       " '76001',\n",
       " '76251',\n",
       " '76501',\n",
       " '76751',\n",
       " '77001',\n",
       " '77251',\n",
       " '77501',\n",
       " '77751',\n",
       " '78001',\n",
       " '78251',\n",
       " '78501',\n",
       " '78751',\n",
       " '79001',\n",
       " '79251',\n",
       " '79501',\n",
       " '79751',\n",
       " '80001',\n",
       " '80251',\n",
       " '80501',\n",
       " '80751',\n",
       " '81001',\n",
       " '81251',\n",
       " '81501',\n",
       " '81751',\n",
       " '82001',\n",
       " '82251',\n",
       " '82501',\n",
       " '82751',\n",
       " '83001',\n",
       " '83251',\n",
       " '83501',\n",
       " '83751',\n",
       " '84001',\n",
       " '84251',\n",
       " '84501',\n",
       " '84751',\n",
       " '85001',\n",
       " '85251',\n",
       " '85501',\n",
       " '85751',\n",
       " '86001',\n",
       " '86251',\n",
       " '86501',\n",
       " '86751',\n",
       " '87001',\n",
       " '87251',\n",
       " '87501',\n",
       " '87751',\n",
       " '88001',\n",
       " '88251',\n",
       " '88501',\n",
       " '88751',\n",
       " '89001',\n",
       " '89251',\n",
       " '89501',\n",
       " '89751',\n",
       " '90001',\n",
       " '90251',\n",
       " '90501',\n",
       " '90751',\n",
       " '91001',\n",
       " '91251',\n",
       " '91501',\n",
       " '91751',\n",
       " '92001',\n",
       " '92251',\n",
       " '92501',\n",
       " '92751',\n",
       " '93001',\n",
       " '93251',\n",
       " '93501',\n",
       " '93751',\n",
       " '94001',\n",
       " '94251',\n",
       " '94501',\n",
       " '94751',\n",
       " '95001',\n",
       " '95251',\n",
       " '95501',\n",
       " '95751',\n",
       " '96001',\n",
       " '96251',\n",
       " '96501',\n",
       " '96751',\n",
       " '97001',\n",
       " '97251',\n",
       " '97501',\n",
       " '97751',\n",
       " '98001',\n",
       " '98251',\n",
       " '98501',\n",
       " '98751',\n",
       " '99001',\n",
       " '99251',\n",
       " '99501',\n",
       " '99751',\n",
       " '100001',\n",
       " '100251',\n",
       " '100501',\n",
       " '100751',\n",
       " '101001',\n",
       " '101251',\n",
       " '101501',\n",
       " '101751',\n",
       " '102001',\n",
       " '102251',\n",
       " '102501',\n",
       " '102751',\n",
       " '103001',\n",
       " '103251',\n",
       " '103501',\n",
       " '103751',\n",
       " '104001',\n",
       " '104251',\n",
       " '104501',\n",
       " '104751',\n",
       " '105001',\n",
       " '105251',\n",
       " '105501',\n",
       " '105751',\n",
       " '106001',\n",
       " '106251',\n",
       " '106501',\n",
       " '106751',\n",
       " '107001',\n",
       " '107251',\n",
       " '107501',\n",
       " '107751',\n",
       " '108001',\n",
       " '108251',\n",
       " '108501',\n",
       " '108751',\n",
       " '109001',\n",
       " '109251',\n",
       " '109501',\n",
       " '109751',\n",
       " '110001',\n",
       " '110251',\n",
       " '110501',\n",
       " '110751',\n",
       " '111001',\n",
       " '111251',\n",
       " '111501',\n",
       " '111751',\n",
       " '112001',\n",
       " '112251',\n",
       " '112501',\n",
       " '112751',\n",
       " '113001',\n",
       " '113251',\n",
       " '113501',\n",
       " '113751',\n",
       " '114001',\n",
       " '114251',\n",
       " '114501',\n",
       " '114751',\n",
       " '115001',\n",
       " '115251',\n",
       " '115501',\n",
       " '115751',\n",
       " '116001',\n",
       " '116251',\n",
       " '116501',\n",
       " '116751',\n",
       " '117001',\n",
       " '117251',\n",
       " '117501',\n",
       " '117751',\n",
       " '118001',\n",
       " '118251',\n",
       " '118501',\n",
       " '118751',\n",
       " '119001',\n",
       " '119251',\n",
       " '119501',\n",
       " '119751',\n",
       " '120001',\n",
       " '120251',\n",
       " '120501',\n",
       " '120751',\n",
       " '121001',\n",
       " '121251',\n",
       " '121501',\n",
       " '121751',\n",
       " '122001',\n",
       " '122251',\n",
       " '122501',\n",
       " '122751',\n",
       " '123001',\n",
       " '123251',\n",
       " '123501',\n",
       " '123751',\n",
       " '124001',\n",
       " '124251',\n",
       " '124501',\n",
       " '124751',\n",
       " '125001',\n",
       " '125251',\n",
       " '125501',\n",
       " '125751',\n",
       " '126001',\n",
       " '126251',\n",
       " '126501',\n",
       " '126751',\n",
       " '127001',\n",
       " '127251',\n",
       " '127501',\n",
       " '127751',\n",
       " '128001',\n",
       " '128251',\n",
       " '128501',\n",
       " '128751',\n",
       " '129001',\n",
       " '129251',\n",
       " '129501',\n",
       " '129751',\n",
       " '130001',\n",
       " '130251',\n",
       " '130501',\n",
       " '130751',\n",
       " '131001',\n",
       " '131251',\n",
       " '131501',\n",
       " '131751',\n",
       " '132001',\n",
       " '132251',\n",
       " '132501',\n",
       " '132751',\n",
       " '133001',\n",
       " '133251',\n",
       " '133501',\n",
       " '133751',\n",
       " '134001',\n",
       " '134251',\n",
       " '134501',\n",
       " '134751',\n",
       " '135001',\n",
       " '135251',\n",
       " '135501',\n",
       " '135751',\n",
       " '136001',\n",
       " '136251',\n",
       " '136501',\n",
       " '136751',\n",
       " '137001',\n",
       " '137251',\n",
       " '137501',\n",
       " '137751',\n",
       " '138001',\n",
       " '138251',\n",
       " '138501',\n",
       " '138751',\n",
       " '139001',\n",
       " '139251',\n",
       " '139501',\n",
       " '139751']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = [str(i) for i in range(15001,140000,250)]\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [1,2,3,4,5,6,7,8,9,10]\n",
    "del list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
